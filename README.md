# Awesome-Consistency-Models

### Conference

- Consistency Models (**ICML 2023**)[[paper](https://arxiv.org/abs/2303.01469)]

- Improved Techniques for Training Consistency Models (**ICLR 2024**)[[paper](https://arxiv.org/abs/2310.14189)]

- Consistency Trajectory Models: Learning Probability Flow ODE Trajectory of Diffusion  (**ICLR 2024**)[[paper](https://arxiv.org/abs/2310.02279)]

- ACT-Diffusion: Efficient Adversarial Consistency Training for One-step Diffusion Models (**CVPR 2024**)[[paper](https://arxiv.org/abs/2311.14097)]

- CoMoSpeech: One-Step Speech and Singing Voice Synthesis via Consistency Model (**ACM MM 2023**)[[paper](https://arxiv.org/abs/2305.06908)]


### Preprint

- AnimateLCM: Accelerating the Animation of Personalized Diffusion Models and Adapters with Decoupled Consistency Learning (**arXiv 2024**)[[paper](https://arxiv.org/abs/2402.00769)]

- RL for Consistency Models: Faster Reward Guided Text-to-Image Generation (**arXiv 2024**) [[paper](https://arxiv.org/abs/2404.03673)]

- Latent Consistency Models: Synthesizing High-Resolution Images with Few-step Inference (**arXiv 2023**) [[paper](https://arxiv.org/abs/2310.04378)]

- Music Consistency Models (**arXiv 2024**) [[paper](https://arxiv.org/abs/2404.13358)]

- Multistep Consistency Models (**arXiv 2024**) [[paper](https://arxiv.org/abs/2403.06807)]
- Towards a mathematical theory for consistency training in diffusion models (**arXiv 2024**) [[paper](https://arxiv.org/abs/2402.07802)]
- Convergence guarantee for consistency models (**arXiv 2023**) [[paper](https://arxiv.org/abs/2308.11449)]

- SCott: Accelerating Diffusion Models with Stochastic Consistency Distillation (**arXiv 2024**) [[paper](https://arxiv.org/abs/2403.01505)]

- CCM: Adding Conditional Controls to Text-to-Image Consistency Models (**arXiv 2023**) [[paper](https://arxiv.org/abs/2312.06971)]

- Bidirectional Consistency Models (**arXiv 2024**) [[paper](https://arxiv.org/abs/2403.18035)]

- Generalized Consistency Trajectory Models for Image Manipulation (**arXiv 2024**) [[paper](https://arxiv.org/abs/2403.12510)]

> If you find your work missing, please PR.

